---
layout: post
title: "RDB Loader 0.13.0 released"
title-short: RDB Loader Loader 0.9.0
tags: [redshift, postgres, shred, relational databases, storage]
author: Anton
category: Releases
---

We are thrilled to announce [version 0.13.0][release-0130] of Relational Database Loader, 
our component that lets you load your enriched data into relational storages like Redshift or Postgres.

This release marks the shift of RDB Loader from part of snowplow monorepository to independent component as well as merge with RDB Shredder component.

<!--more-->

In this post, we will cover:

1. [Dedicated repository](/blog/2017/09/05/rdb-loader-0.13.0-released#separate-project)
2. [Single folder load](/blog/2017/09/05/rdb-loader-0.13.0-released#folder)
3. [Dry run](/blog/2017/09/05/rdb-loader-0.13.0-released#dry-run)
5. [Upgrading](/blog/2017/09/05/rdb-loader-0.13.0-released#upgrading)
6. [Roadmap](/blog/2017/09/05/rdb-loader-0.13.0-released#roadmap)
7. [Contributing](/blog/2017/09/05/rdb-loader-0.13.0-released#contributing)

<h2 id="separate-project">1. Dedicated repository</h2>

This change is mostly transparent for end-users, but still extremely important to note.
Historically, main [snowplow repository][snowplow-repo] contained all components required to load data into different storage targets.
This approach worked well, while AWS Redshift could be considered primary one, but we're gradually moving towards multiple equal storage targets.

This means that we're starting to publish new separate loader components: first one was [Elasticsearch Loader][es-loader-090], now we're moving RDB Loader and many more to come.

RDB Shredder Spark job is now also part of RDB Loader repository, as they always were two tightly coupled components and may share many.

<h2 id="folder">2. Single folder load</h2>

Quite often pipeline operator needs to load one particular archived directory. Either after pipeline recovery or for test purposes.
Before 0.13.0 the only way was to copy/move entirely directory from archive to `shredded.good` and launch pipeline without enrich and shred jobs, pretending they're already completed.
But file-moves are slow and error-prone, that's why we're introducing new `--folder` option, which allows you to load exactly one directory using only RDB Loader.

Unfortunately, there's no support of it in EmrEtlRunner and you you have to either run it locally using helper script or write Dataflow Runner playbook with base64-encoded config files instead of file paths.

Full invocation example:

{% highlight bash %}
$ java -jar $JARFILE \
  --skip consistency_check \
  --config $BASE64_CONFIG \
  --target $BASE64_TARGET \
  --resolver $BASE64_RESOLVER \
  --folder s3://com-acme-snowplow/archive/shredded/run=2017-09-05-13-30-22 \
  --logkey s3//com-acme-snowplow/log/rdb-loader/$(uuid) 
%{ endhighlight  %}

You can find full example script in our recent [discourse post][discourse-r90-alert].


<h2 id="dry-run">3. Dry run</h2>




<h2 id="other">3. Other changes</h2>





<h2 id="upgrading">5. Upgrading</h2>

Primary way to run RDB Loader is still Snowplow EmrEtlRunner R90+. You need to updated `config.yml`:

{% highlight yaml %}
storage:
  versions:
    rdb_loader: 0.13.0        # WAS 0.12.0
{% endhighlight %}


<h2 id="roadmap">6. Roadmap</h2>



<h2 id="contributing">7. Contributing</h2>

You can check out the [repository][repo] and the
[open issues](https://github.com/snowplow/snowplow-rdb-loader/issues?utf8=âœ“&q=is%3Aissue%20is%3Aopen%20)
if you'd like to get involved!

[repo]: https://github.com/snowplow/snowplow-rdb-loader

[snowplow-repo]: https://github.com/snowplow/snowplow
[el-loader-090]: https://snowplowanalytics.com/blog/2017/07/21/elasticsearch-loader-0.9.0-released/

[discourse-spark-tutorial]: https://discourse.snowplowanalytics.com/t/replacing-amazon-redshift-with-apache-spark-for-event-data-modeling-tutorial/1259
[discourse-r90-alert]: https://discourse.snowplowanalytics.com/t/important-alert-r90-r91-bug-may-result-in-shredded-types-not-loading-into-redshift-after-recovery/1422

